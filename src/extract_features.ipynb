{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from JSON file\n",
    "- Create empty dataframe\n",
    "- Loop on every question/answer pair in the file\n",
    "- Add a row to the dataframe for each pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "question_df = pd.DataFrame(columns=[\"Question\",\"Context\",\"Text answer\",\"Answer start\"])\n",
    "\n",
    "FILE_PATH = \"../data/\"\n",
    "\n",
    "with open(FILE_PATH+'train.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    for book in data['data']:\n",
    "        for paragraph in book['paragraphs']:\n",
    "            for question in paragraph['qas']:\n",
    "                row = pd.Series(data={'Question' : question['question'],\n",
    "                                      'Context' : paragraph['context'],\n",
    "                                      'Text answer': question['answers'][0]['answer_start'],\n",
    "                                      'Answer start': question['answers'][0]['text']})\n",
    "                question_df = question_df.append(row,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Context</th>\n",
       "      <th>Text answer</th>\n",
       "      <th>Answer start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quel astronome a émit l'idée en premier d'une ...</td>\n",
       "      <td>L'idée selon laquelle une planète inconnue pou...</td>\n",
       "      <td>136</td>\n",
       "      <td>Johann Elert Bode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quel astronome découvrit Uranus ?</td>\n",
       "      <td>L'idée selon laquelle une planète inconnue pou...</td>\n",
       "      <td>404</td>\n",
       "      <td>William Herschel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quelles furent les découvertes finales des vin...</td>\n",
       "      <td>L'idée selon laquelle une planète inconnue pou...</td>\n",
       "      <td>733</td>\n",
       "      <td>plusieurs autres astéroïdes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quelles furent les découvertes finales des vin...</td>\n",
       "      <td>L'idée selon laquelle une planète inconnue pou...</td>\n",
       "      <td>733</td>\n",
       "      <td>plusieurs autres astéroïdes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Combien de fois Piazzi est-il parvenu à observ...</td>\n",
       "      <td>Piazzi observa Cérès 24 fois, la dernière fois...</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20726</th>\n",
       "      <td>Qui publie un ouvrage en 1810 ?</td>\n",
       "      <td>À partir du XVIIe siècle, les fouilles se spéc...</td>\n",
       "      <td>761</td>\n",
       "      <td>Giuseppe Micali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20727</th>\n",
       "      <td>Quel pape organise un musée grégorien ?</td>\n",
       "      <td>Au XIXe siècle, bon nombre de sépultures sont ...</td>\n",
       "      <td>409</td>\n",
       "      <td>Grégoire XVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20728</th>\n",
       "      <td>Où se trouve le musée grégorien ?</td>\n",
       "      <td>Au XIXe siècle, bon nombre de sépultures sont ...</td>\n",
       "      <td>450</td>\n",
       "      <td>au Vatican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20729</th>\n",
       "      <td>Qui vole à grande échelle ?</td>\n",
       "      <td>Au XIXe siècle, bon nombre de sépultures sont ...</td>\n",
       "      <td>959</td>\n",
       "      <td>les tombaroli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20730</th>\n",
       "      <td>Quand se poursuit la confection de faux ?</td>\n",
       "      <td>Au XIXe siècle, bon nombre de sépultures sont ...</td>\n",
       "      <td>1020</td>\n",
       "      <td>XIXe et XXe siècles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20731 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Question  \\\n",
       "0      Quel astronome a émit l'idée en premier d'une ...   \n",
       "1                      Quel astronome découvrit Uranus ?   \n",
       "2      Quelles furent les découvertes finales des vin...   \n",
       "3      Quelles furent les découvertes finales des vin...   \n",
       "4      Combien de fois Piazzi est-il parvenu à observ...   \n",
       "...                                                  ...   \n",
       "20726                    Qui publie un ouvrage en 1810 ?   \n",
       "20727            Quel pape organise un musée grégorien ?   \n",
       "20728                  Où se trouve le musée grégorien ?   \n",
       "20729                        Qui vole à grande échelle ?   \n",
       "20730          Quand se poursuit la confection de faux ?   \n",
       "\n",
       "                                                 Context Text answer  \\\n",
       "0      L'idée selon laquelle une planète inconnue pou...         136   \n",
       "1      L'idée selon laquelle une planète inconnue pou...         404   \n",
       "2      L'idée selon laquelle une planète inconnue pou...         733   \n",
       "3      L'idée selon laquelle une planète inconnue pou...         733   \n",
       "4      Piazzi observa Cérès 24 fois, la dernière fois...          21   \n",
       "...                                                  ...         ...   \n",
       "20726  À partir du XVIIe siècle, les fouilles se spéc...         761   \n",
       "20727  Au XIXe siècle, bon nombre de sépultures sont ...         409   \n",
       "20728  Au XIXe siècle, bon nombre de sépultures sont ...         450   \n",
       "20729  Au XIXe siècle, bon nombre de sépultures sont ...         959   \n",
       "20730  Au XIXe siècle, bon nombre de sépultures sont ...        1020   \n",
       "\n",
       "                      Answer start  \n",
       "0                Johann Elert Bode  \n",
       "1                 William Herschel  \n",
       "2      plusieurs autres astéroïdes  \n",
       "3      plusieurs autres astéroïdes  \n",
       "4                               24  \n",
       "...                            ...  \n",
       "20726              Giuseppe Micali  \n",
       "20727                 Grégoire XVI  \n",
       "20728                   au Vatican  \n",
       "20729                les tombaroli  \n",
       "20730          XIXe et XXe siècles  \n",
       "\n",
       "[20731 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(question_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import fasttext\n",
    "# Load vector directly from the file\n",
    "def load_model():\n",
    "    try:\n",
    "        # model = KeyedVectors.load_word2vec_format('../model/frWac_postag_no_phrase_1000_skip_cut100.bin', binary=True)\n",
    "        model = fasttext.load_model(\"../model/cc.fr.300.bin\")\n",
    "        print(\"model loaded\")\n",
    "        return model\n",
    "    except:\n",
    "        print(\"model not found\")\n",
    "        \n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_WordVector(word,model):\n",
    "    # Check if a word exists in the model\n",
    "    try:\n",
    "        vector = model[word]\n",
    "        return vector\n",
    "    except:\n",
    "        print(\"Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute cosine distance between 2 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def get_cosine_distance(word_vec_1,word_vec_2):\n",
    "    return (1 - spatial.distance.cosine(word_vec_1, word_vec_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3769944906234741\n"
     ]
    }
   ],
   "source": [
    "print(get_cosine_distance(get_WordVector(\"manger\",model),get_WordVector(\"pleurer\",model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute sentence vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize(sentence): \n",
    "    return word_tokenize(sentence, language='french')\n",
    "  \n",
    "def get_SentenceVector(sentence,model):\n",
    "    # splitted_sentence = tokenize(sentence)\n",
    "    list_word_vectors = list()\n",
    "    list_words = list()\n",
    "\n",
    "    for word in sentence:\n",
    "        word_vec = get_WordVector(word,model)\n",
    "        list_word_vectors.append(word_vec)\n",
    "        list_words.append(word)\n",
    "    return sum(list_word_vectors)/len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9729830622673035\n",
      "0.9260295629501343\n"
     ]
    }
   ],
   "source": [
    "sentence_vec_1 = get_SentenceVector(\"Je mange des nougats le matin\",model)\n",
    "sentence_vec_2 = get_SentenceVector(\"Je mange des pommes\",model)\n",
    "print(get_cosine_distance(sentence_vec_1,sentence_vec_2))\n",
    "\n",
    "sentence_vec_1 = get_SentenceVector(\"Je dors la nuit et je vole le jour\",model)\n",
    "sentence_vec_2 = get_SentenceVector(\"Je mange des pommes\",model)\n",
    "print(get_cosine_distance(sentence_vec_1,sentence_vec_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "def rm_stop_words_nltk(sentence):\n",
    "    stopWords = set(stopwords.words('french'))\n",
    "    words = word_tokenize(sentence)\n",
    "    wordsFiltered = []\n",
    "    for w in words:\n",
    "        if w not in stopWords:\n",
    "            wordsFiltered.append(w)\n",
    "    return wordsFiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
    "final_stopwords_list = list(fr_stop)\n",
    "\n",
    "def rm_stop_words_spacy(sentence):\n",
    "    final_stopwords_list = list(fr_stop)\n",
    "    words = word_tokenize(sentence)\n",
    "    wordsFiltered = []\n",
    "    for w in words:\n",
    "        if w not in final_stopwords_list:\n",
    "            wordsFiltered.append(w)\n",
    "    return wordsFiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Je', 'dors', 'nuit', 'vole', 'jour', 'lit', 'fait', 'taille', 'mongolfiere']\n",
      "['Je', 'dors', 'nuit', 'vole', 'jour', 'lit', 'taille', 'mongolfiere']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Je dors la nuit et je vole le jour sur un lit qui fait la taille de une mongolfiere\"\n",
    "print(rm_stop_words_nltk(sentence))\n",
    "print(rm_stop_words_spacy(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove all non-alphanumeric characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bonjour comment allez vous\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def remove_non_alphanum_chars(sentence):\n",
    "    return re.sub(r'([^\\s\\w]|_)+', '', sentence)\n",
    "\n",
    "import string\n",
    "def remove_non_alphanum_chars(s):\n",
    "    return s.translate(str.maketrans('', '', string.punctuation))\n",
    "print (remove_non_alphanum_chars(\"bonjour, comment allez vous?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je mappelle Basile je suis pauvre Je mange des gateaux\n"
     ]
    }
   ],
   "source": [
    "print(remove_non_alphanum_chars(\"Je m'appelle Basile, je suis pauvre. Je mange des gateaux.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    # Add pre-processing steps\n",
    "    sentence = remove_non_alphanum_chars(sentence)\n",
    "    sentence = rm_stop_words_spacy(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get sentence answer number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_answer_num(sent_list,ans_start):\n",
    "    matched_indexes = []\n",
    "    #print(\"ans_start : \",ans_start)\n",
    "    i = -1\n",
    "    cpt = 0\n",
    "    while cpt < ans_start:\n",
    "        #print(i+1)\n",
    "        cpt = cpt + len(sent_list[i+1])\n",
    "        #print(cpt)\n",
    "        i += 1\n",
    "        \n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_answer_num(sent_list,ans):\n",
    "    matched_indexes = []\n",
    "    #print(\"ans_start : \",ans_start)\n",
    "    ind = 0\n",
    "    for index,sent in enumerate(sent_list):\n",
    "        if ans in sent:\n",
    "            ind = index\n",
    "            break\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split text into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "list_len_context = list()\n",
    "feature_df = pd.DataFrame(columns=[\"Question\",\"Sentences\",\"Answer index\",\"Answer\"])\n",
    "true_cpt = 0\n",
    "false_cpt = 0\n",
    "\n",
    "\n",
    "for index, row in question_df.iterrows():\n",
    "    splitted_context = nltk.tokenize.sent_tokenize(row['Context'])   \n",
    "    index_answer = get_sentence_answer_num(splitted_context,row['Answer start'])\n",
    "    list_len_context.append(len(splitted_context))\n",
    "    list_preprocessed_sentences = list()\n",
    "    question = row['Question']\n",
    "    preprocessed_question = preprocess(question)\n",
    "\n",
    "    for sentence in splitted_context:\n",
    "        preprocessed_sentence = preprocess(sentence)\n",
    "        if len(sentence) != 0:\n",
    "            list_preprocessed_sentences.append(preprocessed_sentence)\n",
    "                 \n",
    "    row = pd.Series(data={'Question' : question,\n",
    "                          'Sentences': list_preprocessed_sentences,\n",
    "                          'Answer index' : index_answer,\n",
    "                          'Answer' : row['Answer start']})\n",
    "    feature_df = feature_df.append(row,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(list_len_context, density=True, bins=max(list_len_context))  # `density=False` would make counts\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Data');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.905937967295355\n",
      "23\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Python program to get average of a list \n",
    "def Average(lst): \n",
    "    return sum(lst) / len(lst) \n",
    "\n",
    "print(Average(list_len_context))\n",
    "print(max(list_len_context))\n",
    "print(min(list_len_context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false_cpt :  0\n",
      "true_cpt :  0\n"
     ]
    }
   ],
   "source": [
    "print(\"false_cpt : \",false_cpt)\n",
    "print(\"true_cpt : \",true_cpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the dataframe to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.to_csv('../data/train.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
