{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from JSON file\n",
    "- Create empty dataframe\n",
    "- Loop on every question/answer pair in the file\n",
    "- Add a row to the dataframe for each pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "question_df = pd.DataFrame(columns=[\"Question\",\"Context\",\"Text answer\",\"Answer start\"])\n",
    "\n",
    "FILE_PATH = \"../data/\"\n",
    "\n",
    "with open(FILE_PATH+'valid.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    for book in data['data']:\n",
    "        for paragraph in book['paragraphs']:\n",
    "            for question in paragraph['qas']:\n",
    "                row = pd.Series(data={'Question' : question['question'],\n",
    "                                      'Context' : paragraph['context'],\n",
    "                                      'Text answer': question['answers'][0]['answer_start'],\n",
    "                                      'Answer start': question['answers'][0]['text']})\n",
    "                question_df = question_df.append(row,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Context</th>\n",
       "      <th>Text answer</th>\n",
       "      <th>Answer start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Que concerne principalement les documents ?</td>\n",
       "      <td>Les deux tableaux sont certes décrits par des ...</td>\n",
       "      <td>161</td>\n",
       "      <td>La Vierge aux rochers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Par quoi sont décrit les deux tableaux ?</td>\n",
       "      <td>Les deux tableaux sont certes décrits par des ...</td>\n",
       "      <td>46</td>\n",
       "      <td>documents contemporains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quels types d'objets sont les deux tableaux au...</td>\n",
       "      <td>Les deux tableaux sont certes décrits par des ...</td>\n",
       "      <td>204</td>\n",
       "      <td>objets de spéculations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sur quelle jambe les personnages se tiennent-t...</td>\n",
       "      <td>Les deux panneaux présentent de nombreuses sim...</td>\n",
       "      <td>242</td>\n",
       "      <td>droite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quel pied avancent les personnages ?</td>\n",
       "      <td>Les deux panneaux présentent de nombreuses sim...</td>\n",
       "      <td>271</td>\n",
       "      <td>gauche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>A quel risque la zone où se situe la chapelle ...</td>\n",
       "      <td>La chapelle se trouvant dans une zone inondabl...</td>\n",
       "      <td>33</td>\n",
       "      <td>zone inondable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>Comment était disposés les murets par rapport ...</td>\n",
       "      <td>La chapelle se trouvant dans une zone inondabl...</td>\n",
       "      <td>210</td>\n",
       "      <td>perpendiculaires au courant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>En quelle matière sont les dalles du canal ?</td>\n",
       "      <td>La chapelle se trouvant dans une zone inondabl...</td>\n",
       "      <td>322</td>\n",
       "      <td>schiste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>Par quoi le canal est-il doublé ?</td>\n",
       "      <td>La chapelle se trouvant dans une zone inondabl...</td>\n",
       "      <td>479</td>\n",
       "      <td>par une digue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>A quoi devaient servir les terrasses ?</td>\n",
       "      <td>La chapelle se trouvant dans une zone inondabl...</td>\n",
       "      <td>1060</td>\n",
       "      <td>terrains agricoles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3188 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Question  \\\n",
       "0           Que concerne principalement les documents ?   \n",
       "1              Par quoi sont décrit les deux tableaux ?   \n",
       "2     Quels types d'objets sont les deux tableaux au...   \n",
       "3     Sur quelle jambe les personnages se tiennent-t...   \n",
       "4                 Quel pied avancent les personnages ?    \n",
       "...                                                 ...   \n",
       "3183  A quel risque la zone où se situe la chapelle ...   \n",
       "3184  Comment était disposés les murets par rapport ...   \n",
       "3185       En quelle matière sont les dalles du canal ?   \n",
       "3186                  Par quoi le canal est-il doublé ?   \n",
       "3187             A quoi devaient servir les terrasses ?   \n",
       "\n",
       "                                                Context Text answer  \\\n",
       "0     Les deux tableaux sont certes décrits par des ...         161   \n",
       "1     Les deux tableaux sont certes décrits par des ...          46   \n",
       "2     Les deux tableaux sont certes décrits par des ...         204   \n",
       "3     Les deux panneaux présentent de nombreuses sim...         242   \n",
       "4     Les deux panneaux présentent de nombreuses sim...         271   \n",
       "...                                                 ...         ...   \n",
       "3183  La chapelle se trouvant dans une zone inondabl...          33   \n",
       "3184  La chapelle se trouvant dans une zone inondabl...         210   \n",
       "3185  La chapelle se trouvant dans une zone inondabl...         322   \n",
       "3186  La chapelle se trouvant dans une zone inondabl...         479   \n",
       "3187  La chapelle se trouvant dans une zone inondabl...        1060   \n",
       "\n",
       "                     Answer start  \n",
       "0           La Vierge aux rochers  \n",
       "1         documents contemporains  \n",
       "2          objets de spéculations  \n",
       "3                          droite  \n",
       "4                          gauche  \n",
       "...                           ...  \n",
       "3183               zone inondable  \n",
       "3184  perpendiculaires au courant  \n",
       "3185                      schiste  \n",
       "3186                par une digue  \n",
       "3187           terrains agricoles  \n",
       "\n",
       "[3188 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(question_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import fasttext\n",
    "# Load vector directly from the file\n",
    "def load_model():\n",
    "    try:\n",
    "        # model = KeyedVectors.load_word2vec_format('../model/frWac_postag_no_phrase_1000_skip_cut100.bin', binary=True)\n",
    "        model = fasttext.load_model(\"../model/cc.fr.300.bin\")\n",
    "        print(\"model loaded\")\n",
    "        return model\n",
    "    except:\n",
    "        print(\"model not found\")\n",
    "        \n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_WordVector(word,model):\n",
    "    # Check if a word exists in the model\n",
    "    try:\n",
    "        vector = model[word]\n",
    "        return vector\n",
    "    except:\n",
    "        print(\"Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute cosine distance between 2 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def get_cosine_distance(word_vec_1,word_vec_2):\n",
    "    return (1 - spatial.distance.cosine(word_vec_1, word_vec_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3769944906234741\n"
     ]
    }
   ],
   "source": [
    "print(get_cosine_distance(get_WordVector(\"manger\",model),get_WordVector(\"pleurer\",model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute sentence vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize(sentence): \n",
    "    return word_tokenize(sentence, language='french')\n",
    "  \n",
    "def get_SentenceVector(sentence,model):\n",
    "    # splitted_sentence = tokenize(sentence)\n",
    "    list_word_vectors = list()\n",
    "    list_words = list()\n",
    "\n",
    "    for word in sentence:\n",
    "        word_vec = get_WordVector(word,model)\n",
    "        list_word_vectors.append(word_vec)\n",
    "        list_words.append(word)\n",
    "    return sum(list_word_vectors)/len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86665940284729\n",
      "0.7887915968894958\n"
     ]
    }
   ],
   "source": [
    "sentence_vec_1 = get_SentenceVector(\"Je mange des nougats le matin\",model)\n",
    "sentence_vec_2 = get_SentenceVector(\"Je mange des pommes\",model)\n",
    "print(get_cosine_distance(sentence_vec_1,sentence_vec_2))\n",
    "\n",
    "sentence_vec_1 = get_SentenceVector(\"Je dors la nuit et je vole le jour\",model)\n",
    "sentence_vec_2 = get_SentenceVector(\"Je mange des pommes\",model)\n",
    "print(get_cosine_distance(sentence_vec_1,sentence_vec_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "def rm_stop_words_nltk(sentence):\n",
    "    stopWords = set(stopwords.words('french'))\n",
    "    words = word_tokenize(sentence)\n",
    "    wordsFiltered = []\n",
    "    for w in words:\n",
    "        if w not in stopWords:\n",
    "            wordsFiltered.append(w)\n",
    "    return wordsFiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
    "final_stopwords_list = list(fr_stop)\n",
    "\n",
    "def rm_stop_words_spacy(sentence):\n",
    "    final_stopwords_list = list(fr_stop)\n",
    "    words = word_tokenize(sentence)\n",
    "    wordsFiltered = []\n",
    "    for w in words:\n",
    "        if w not in final_stopwords_list:\n",
    "            wordsFiltered.append(w)\n",
    "    return wordsFiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Je', 'dors', 'nuit', 'vole', 'jour', 'lit', 'fait', 'taille', 'mongolfiere']\n",
      "['Je', 'dors', 'nuit', 'vole', 'jour', 'lit', 'taille', 'mongolfiere']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Je dors la nuit et je vole le jour sur un lit qui fait la taille de une mongolfiere\"\n",
    "print(rm_stop_words_nltk(sentence))\n",
    "print(rm_stop_words_spacy(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove all non-alphanumeric characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alphanum_chars(sentence):\n",
    "    return re.sub(r'([^\\s\\w]|_)+', '', sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je mappelle Basile je suis pauvre Je mange des gateaux\n"
     ]
    }
   ],
   "source": [
    "print(remove_non_alphanum_chars(\"Je m'appelle Basile, je suis pauvre. Je mange des gateaux.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    # Add pre-processing steps\n",
    "    sentence = remove_non_alphanum_chars(sentence)\n",
    "    sentence = rm_stop_words_spacy(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split text into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "list_len_context = list()\n",
    "\n",
    "for index, row in question_df.iterrows():\n",
    "    splitted_context = nltk.tokenize.sent_tokenize(row['Context'])\n",
    "    list_len_context.append(len(splitted_context))\n",
    "    for sentence in splitted_context:\n",
    "        sentence = preprocess(sentence)\n",
    "        if len(sentence) != 0:\n",
    "            sentence_vector = get_SentenceVector(sentence,model)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(list_len_context, density=True, bins=20)  # `density=False` would make counts\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Data');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.4912170639899625\n",
      "20\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Python program to get average of a list \n",
    "def Average(lst): \n",
    "    return sum(lst) / len(lst) \n",
    "\n",
    "print(Average(list_len_context))\n",
    "print(max(list_len_context))\n",
    "print(min(list_len_context))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the dataframe to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(df):\n",
    "    # Savess"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
